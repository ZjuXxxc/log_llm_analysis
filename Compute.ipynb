{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a57009",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compute_ece(confidences, accuracies, n_bins=10):\n",
    "    \"\"\"Expected Calibration Error\"\"\"\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        mask = (confidences >= bins[i]) & (confidences < bins[i + 1])\n",
    "        if np.any(mask):\n",
    "            acc_bin = np.mean(accuracies[mask])\n",
    "            conf_bin = np.mean(confidences[mask])\n",
    "            ece += np.abs(acc_bin - conf_bin) * np.mean(mask)\n",
    "    return ece\n",
    "\n",
    "def analyze_log_folder(folder=\"log_llm\"):\n",
    "    all_confs, all_accs = [], []\n",
    "\n",
    "    results = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if not filename.endswith(\".json\"):\n",
    "            continue\n",
    "        with open(os.path.join(folder, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        rolls = data.get(\"each_roll\", [])\n",
    "        confs = np.array([r[\"confidence\"] for r in rolls if r.get(\"confidence\") is not None])\n",
    "        accs  = np.array([r[\"accuracy\"]   for r in rolls if r.get(\"accuracy\")   is not None])\n",
    "        \n",
    "        if len(confs) == 0: continue\n",
    "\n",
    "        mean_conf_correct = confs[accs == 1].mean() if np.any(accs == 1) else np.nan\n",
    "        mean_conf_wrong   = confs[accs == 0].mean() if np.any(accs == 0) else np.nan\n",
    "        delta = mean_conf_correct - mean_conf_wrong if not np.isnan(mean_conf_correct) and not np.isnan(mean_conf_wrong) else np.nan\n",
    "        \n",
    "        # 汇总全局统计\n",
    "        all_confs.extend(confs)\n",
    "        all_accs.extend(accs)\n",
    "\n",
    "        results.append({\n",
    "            \"file\": filename,\n",
    "            \"mean_conf_correct\": mean_conf_correct,\n",
    "            \"mean_conf_wrong\": mean_conf_wrong,\n",
    "            \"delta\": delta,\n",
    "            \"acc_rate\": np.mean(accs)\n",
    "        })\n",
    "\n",
    "    # 全局指标\n",
    "    all_confs = np.array(all_confs)\n",
    "    all_accs = np.array(all_accs)\n",
    "\n",
    "    global_stats = {\n",
    "        \"global_mean_conf_correct\": all_confs[all_accs == 1].mean(),\n",
    "        \"global_mean_conf_wrong\": all_confs[all_accs == 0].mean(),\n",
    "        \"global_delta\": all_confs[all_accs == 1].mean() - all_confs[all_accs == 0].mean(),\n",
    "        \"global_auc\": roc_auc_score(all_accs, all_confs) if len(np.unique(all_accs)) > 1 else np.nan,\n",
    "        \"global_ece\": compute_ece(all_confs, all_accs),\n",
    "        \"global_brier\": np.mean((all_confs - all_accs) ** 2),\n",
    "        \"global_acc\": np.mean(all_accs)\n",
    "    }\n",
    "\n",
    "    return results, global_stats\n",
    "\n",
    "results, global_stats = analyze_log_folder(\"log_llm\")\n",
    "\n",
    "print(\"=== 每个文件的统计 ===\")\n",
    "for r in results:\n",
    "    print(r)\n",
    "\n",
    "print(\"\\n=== 全局统计 ===\")\n",
    "for k, v in global_stats.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
